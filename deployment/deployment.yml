# settings configuration for deploying the model to Azure ML Managed Online Endpoint

$schema: https://azuremlschemas.azureedge.net/latest/managedOnlineDeployment.schema.json
name: qwen-deployment-v1
endpoint_name: qwen-endpoint
model: azureml:qwen-7b-custom@latest
environment: 
  conda_file: ../environment/conda.yaml
  image: mcr.microsoft.com/azureml/openmpi4.1.0-cuda11.8-cudnn8-ubuntu22.04:latest
code_configuration:
  code: ../src
  scoring_script: inference.py
instance_type: Standard_NC6s_v3
instance_count: 1
request_settings:
  request_timeout_ms: 90000
  max_concurrent_requests_per_instance: 1
resource_requirements:
  cpu: "6"
  memory: "56Gi"
liveness_probe:
  failure_threshold: 30
  success_threshold: 1
  timeout: 2
  period: 10
  initial_delay: 600
readiness_probe:
  failure_threshold: 30
  success_threshold: 1
  timeout: 2
  period: 10
  initial_delay: 600